{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNwZvdVapgAsRkneNLSuWri",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeadOnGames/gym-env-texasholdem/blob/main/HUNLTH_env.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tq4dCDAmkfDN"
      },
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "import random\n",
        "import gym\n",
        "from gym import spaces\n",
        "from gym.spaces import Box, Discrete\n",
        "from gym import Env\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Actions(Enum):\n",
        "  FOLD = 0\n",
        "  CALL = 1\n",
        "  RAISE = 2\n",
        "  CHECK = 3"
      ],
      "metadata": {
        "id": "J8xG2haUl8ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StageEnum(Enum):\n",
        "  PREFLOP = 0 \n",
        "  FLOP = 1\n",
        "  TURN = 2\n",
        "  RIVER = 3\n",
        "  SHOWDOWN = 4"
      ],
      "metadata": {
        "id": "C92e4R6dmPqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HUNLTH_env(gym.Env):\n",
        "  \"\"\"A Heads-Up No Limit Texas Hold'em environment for OpenAI gym\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    #define environment - currently takes in discrete actions\n",
        "\n",
        "    # Define action space\n",
        "    self.action_space = spaces.Discrete(len(Actions))\n",
        "\n",
        "    #Define observation space\n",
        "    self.observation_space = ...\n",
        "\n",
        "    #Current state - set to random\n",
        "    self.state = ...\n",
        "\n",
        "    #no. of rounds\n",
        "    self.rounds = 20\n",
        "\n",
        "    #reward collected \n",
        "    self.collected_reward = 0\n",
        "\n",
        "  def step(self, action):\n",
        "    # Execute one time step within the environment\n",
        "    ...\n",
        "    \n",
        "  def render(self):\n",
        "    # Render the environment to the screen\n",
        "    ...\n",
        "\n",
        "  def reset(self):\n",
        "    # Reset the state of the environment to an initial state\n",
        "    \n",
        "    ..."
      ],
      "metadata": {
        "id": "Ewo3ZTYhkk29"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}